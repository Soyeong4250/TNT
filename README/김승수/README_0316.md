# 2022-03-16 ✨

## 오늘 한 일 💡
1. 블록체인 기본개념과 작동원리 소개 - 유튜브 라이브
2. Tech Talk - 유튜브 라이브
3. 전문가리뷰 사전 QnA 작성
4. 중간발표자 선정
5. 와이어프레임 구체화
6. 컨설턴트님 팀미팅

## 컨설턴트님 말씀
### 데이터의 출처는?
👉 네이버 뉴스 기사
👉 각 언론사마다 크롤링 해야하는지? 다른 포멧이 있는지?
데이터를 가공하는 타이밍은? 
👉 사용자에게 굉장히 의미있는 부분임
데이터를 가공하는 타이밍은 사용자에게 보여주는 시간도 정해야함
👉 데이터 수집량이 너무 많아서 아무리 빨리 처리한다고 해도 6시에 보여준다고 한다면 최소 5시반에는 분석을 시작해야 함
👉 그럼 5시 59분에 게시한 뉴스는 포함이 되지 않는 것인가?
👉 사용자 입장에서는 최근 이슈와 가장 핫한 이슈들에 대해 보고 싶을텐데 이럴 경우 사용자의 니즈를 만족시키기 어려울 수 있음

### 크롤링의 단점
👉 게시된 글을 이용한 것이므로 언제든지 변경될 가능성이 있음 이때, 우리에게는 예외가 발생한 것이므로, 이에 대한 대응을 대비해야할 것 
👉 사용자가 뉴스의 소스가 잘못되었는지의 판단 유무를 관리자에게 알릴 수 있는 기능이 필요할 듯 

### 데이터 분석 외의 기능
모든 사용자들은 커스텀을 하고 싶어한다.
👉 네이버의 기사의 경우 관심있는 분야의 기사만 선택해서 볼 수 있음.
  이번 서비스 역시 관심있는 키워드를 선택했을 경우 해당 키워드 관련 기사만 메인에 보이게끔 하는 기능 등
👉 실시간 서버는 아니지만 분석 결과가 나오는 하루의 두번이라도 사용자에게 실시간으로 알림이 오는 기능이 있었으면 좋을듯
👉 실제로 사용하는 사람의 입장에서 생각해서 기능을 구현하자

시연할 때 일주일보다 더 많은 양의 기사를 이용하였으면 좋겠다 👉 크롤링의 경우 과거 데이터를 가져오기가 조금 힘들다
👉 옛날 데이터를 쉽게 가져올 수 있는 어떤 서비스를 개발하는 것도 좋을 듯

### 데이터 수집 tip
👉 대전 4기에서 글을 수집하는데에 많은 양의 데이터를 수집함 나름의 병렬처리를 했는데 이를 이용하여 성능이 얼마나 성능했는지 등의 퍼포먼스를 설명함

### 7팀과 유사한 타겟데이터
+ 7팀도 비슷한주제 -언론사기사를 크롤링기법으로 수집함
+ 우리팀은 데이터를 가공하여 정보제공목적의 사이트
+ 7팀은 사용자의 반응에 대해 액션을 취해줌
+ 기획방향은 다르니 그냥 진행시켜도됨
+ 유사한 방향의 아이템이 같은회사에서도 동시에 진행되는경우가 있다.
+ 상부상조하는 방향으로 가는게좋다.
+ **기술을 아는 사람이 다른팀에 있다면 연락해서 세미나식으로 들어도 보고 질문도 하는 기회를 가져보는것도 좋을것같다.**

## 느낀 점 🙄
```
컨설턴트님께 팀미팅을 요청하고 많은 얘기를 들어봤다.  
생각하지 못했던 부분이나 새로운 영감이 떠오르는 시간이었다.  
일종의 커스터마이징 느낌으로 사용자가 구독한 키워드가 오늘의 키워드 순위에 올라온다면 알람이 가는 키워드 구독 시스템을 생각해보았다.  
나쁘지 않은 반응이었고 기획에 추가해보기로 했다.  
7팀과 타겟팅데이터가 비슷하다는 얘기 또한 들었다. 프로젝트의 기획 방향이 달라 그대로 가기로 했고 비슷한 데이터를 비슷한 방식으로 수집한다는 점에서 협업할수 있는 지점이 분명해보였고 추후에 7팀의 팀장님과 컨텍하여 기술공유를 해볼 생각이다.
```
## 내일 할일 🧐
1️⃣ ppt 최종 점검
2️⃣ 빅데이터 분산처리 및 분석을 위한 하둡 에코시스템 활용실습

