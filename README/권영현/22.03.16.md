# 🎩 22.03.16
  
## 오전
1. 블록체인 기본 개념 설명과 작동원리 소개
2. Tech Talk 2 수강
  
---
## 오후
1. 와이어프레임 구체화
2. 컨설턴트님 팀미팅
  
### 컨설턴트 팀미팅
👉 와이어프레임 구체적으로 

👉 네이버 뉴스 기사

👉 각 언론사마다 크롤링 해야하는지? 다른 포멧이 있는지?

👉 데이터를 가공하는 타이밍은?

👉 사용자에게 굉장히 의미있는 부분임

👉 데이터를 가공하는 타이밍은 사용자에게 보여주는 시간도 정해야함

👉 데이터 수집량이 너무 많아서 아무리 빨리 처리한다고 해도 6시에 보여준다고 한다면 최소 5시반에는 분석을 시작해야 함

👉 그럼 5시 59분에 게시한 뉴스는 포함이 되지 않는 것인가?

👉 사용자 입장에서는 최근 이슈와 가장 핫한 이슈들에 대해 보고 싶을텐데 이럴 경우 사용자의 니즈를 만족시키기 어려울 수 있음

👉 크롤링의 단점 고려 또는 예외처리 하는 단계 필요

👉 게시된 글을 이용한 것이므로 언제든지 변경될 가능성이 있음 이때, 우리에게는 예외가 발생한 것이므로, 이에 대한 대응을 대비해야할 것

👉 사용자가 뉴스의 소스가 잘못되었는지의 판단 유무를 관리자에게 알릴 수 있는 기능이 필요할 듯

### **데이터 분석 외의 기능 모든 사용자들은 커스텀을 하고 싶어한다.**

👉 네이버의 기사의 경우 관심있는 분야의 기사만 선택해서 볼 수 있음.

👉 ex) 키워드 구독 시스템

👉 이번 서비스 역시 관심있는 키워드를 선택했을 경우 해당 키워드 관련 기사만 메인에 보이게끔 하는 기능 등

👉 실시간 서버는 아니지만 분석 결과가 나오는 하루의 두번이라도 사용자에게 실시간으로 알림이 오는 기능이 있었으면 좋을듯

👉 실제로 사용하는 사람의 입장에서 생각해서 기능을 구현하자

👉 시연할 때 일주일보다 더 많은 양의 기사를 이용하였으면 좋겠다

👉 크롤링의 경우 과거 데이터를 가져오기가 조금 힘들다

👉 옛날 데이터를 쉽게 가져올 수 있는 어떤 서비스를 개발하는 것도 좋을 듯

데이터 수집 tip

👉 대전 4기에서 글을 수집하는데에 많은 양의 데이터를 수집함 나름의 병렬처리를 했는데 이를 이용하여 성능이 얼마나 성능했는지 등의 퍼포먼스를 설명함
  
--- 

## 향후 할 일 🤔
```
1. 간단한 기술 구현
2. 뉴스 크롤링 방법 정하기 (RSS 활용 여부?)
3. 하둡 실습
```
